\documentclass[twoside,11pt]{article}
\usepackage{jmlr2e}
\begin{document}
\textbf{Interpretable/Explainable and Huamn-in-the-loop RL Survey}

[1] A Survey on Interpretable Reinforcement Learning. Claire  Glanois et al. ArXiv preprint arXiv:2112.13112 (2021).

[2] Explainable ai and reinforcement learningâ€”a systematic review of current approaches and trends. Lindsay Wells and Tomasz Bednarz. Frontiers in artificial intelligence 4 (2021): 48.

[3]A Survey of Human-in-the-loop for Machine Learning. Jingxiao Wu et al. ArXiv preprint arXiv:2108.00941 (2021).


\textbf{Interpretable/Explainable and Huamn-in-the-loop RL Papers}

[1] Explanation augmented feedback in human-in-the-loop reinforcement learning. Guan Lin et al. Human And Machine in-the-Loop Evaluation and Learning Strategies Workshop, NeurIPS 2020.

[2]

\textbf{Learning with Imperfect Human Demonstrations}

[1] Reinforcement learning from imperfect demonstrations. Yang Gao et al. ArXiv preprint arXiv:1802.05313 (2018).

[2]
\end{document}

% Recommended Reading:

generally, I liked this paper as in how it gives a good overview of existing approaches, how they are currently applied, and the challenges that still have to be overcome. I think that the end-result of our paper should look similar (though hopefully with better graphics):
https://arxiv.org/pdf/2108.00941.pdf

As for your section, developing with HITL RL:

This one provides a good overview of the target group and their requirements in chapter 3.1, and also asks about the alignments of xAI model with their intended users-
https://dl.acm.org/doi/pdf/10.1145/3351095.3375624

And this survey is a very good resource for looking up different xAI approaches and where they might be useful:
https://arxiv.org/pdf/2112.13112.pdf